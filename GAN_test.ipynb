{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <DAC8FDCB-770B-356E-BA9C-E2F40A2AA20E> /opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <AE6DCE26-A528-35ED-BB3D-88890D27E6B9> /opt/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
    "import torchvision\n",
    "import lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/adityatandon/Documents/VS Code/Deep_Learning/Final/Data/CIFAR10/cifar-10-batches-py/train_data.pkl'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(\n",
    "    os.path.dirname(os.getcwd()),\n",
    "    \"Final/Data/CIFAR10/cifar-10-batches-py\",\n",
    "    \"train_data.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = os.path.join(os.path.dirname(os.getcwd()), \"Data/CIFAR10/cifar-10-batches-py/data_batch_1\")\n",
    "data_dir = os.path.join(\n",
    "    os.path.dirname(os.getcwd()),\n",
    "    \"Final/Data/CIFAR10/cifar-10-batches-py\",\n",
    "    \"train_data.pkl\",\n",
    ")\n",
    "data_dir_val = os.path.join(\n",
    "    os.path.dirname(os.getcwd()), \"Final/Data/CIFAR10/cifar-10-batches-py/test_batch\"\n",
    ")\n",
    "# batch_size = 2\n",
    "num_in_channels = 3\n",
    "dim_z = 16\n",
    "kern_size = 4\n",
    "lr = 2e-4\n",
    "num_epochs = 3\n",
    "\n",
    "num_disc_feat = 32\n",
    "disc_stride = 1\n",
    "disc_padding_size = 0\n",
    "\n",
    "num_gen_feat = 32\n",
    "gen_stride = 3\n",
    "gen_padding_size = 1\n",
    "\n",
    "mean = 0\n",
    "std = 0.02  # from the DCGAN paper\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.has_mps:\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, \"rb\") as fo:\n",
    "        dict = pickle.load(fo, encoding=\"bytes\")\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(folder_dir):\n",
    "    file_paths = os.listdir(folder_dir)\n",
    "    combined_img_data = []\n",
    "    combined_label_data = []\n",
    "    for file in file_paths:\n",
    "        if \"data_batch\" in file:\n",
    "            combined_img_data.append(\n",
    "                unpickle(os.path.join(folder_dir, file))[b\"data\"]\n",
    "            )\n",
    "            combined_label_data.append(\n",
    "                unpickle(os.path.join(folder_dir, file))[b\"labels\"]\n",
    "            )\n",
    "    combined_img_data = np.concatenate(combined_img_data)\n",
    "    combined_label_data = np.concatenate(combined_label_data)\n",
    "    # with open(os.path.join(folder_dir, \"train_img_data.pkl\"), 'wb') as f:\n",
    "    #     pickle.dump(combined_img_data, f)\n",
    "    # with open(os.path.join(folder_dir, \"train_label_data.pkl\"), 'wb') as f:\n",
    "    #     pickle.dump(combined_label_data, f)\n",
    "\n",
    "    train_data = {}\n",
    "    train_data[b\"data\"] = combined_img_data\n",
    "    train_data[b\"labels\"] = combined_label_data\n",
    "    with open(os.path.join(folder_dir, \"train_data.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(train_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(\n",
    "    os.path.join(\n",
    "        os.path.dirname(os.getcwd()), \"Data/CIFAR10/cifar-10-batches-py\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unpickle(data_dir).keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        super().__init__()\n",
    "        self.train_data = unpickle(data_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = torch.tensor(\n",
    "            self.train_data[b\"data\"][idx].reshape(3, 32, 32),\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        label = torch.tensor(\n",
    "            self.train_data[b\"labels\"][idx], dtype=torch.float32\n",
    "        )\n",
    "        # return img, label\n",
    "        return {\"img\": img, \"label\": label}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_data[b\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        super().__init__()\n",
    "        self.val_data = unpickle(data_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = torch.tensor(\n",
    "            self.val_data[b\"data\"][idx].reshape(3, 32, 32), dtype=torch.float32\n",
    "        )\n",
    "        label = torch.tensor(self.val_data[b\"labels\"][idx], dtype=torch.float32)\n",
    "        # return img, label\n",
    "        return {\"img\": img, \"label\": label}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.val_data[b\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.ngpu = ngpu\n",
    "        self.net = nn.Sequential(\n",
    "            # nn.BatchNorm2d(num_in_channels),\n",
    "            nn.Conv2d(\n",
    "                num_in_channels,\n",
    "                num_disc_feat,\n",
    "                kern_size,\n",
    "                disc_stride,\n",
    "                disc_padding_size,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(\n",
    "                num_disc_feat,\n",
    "                num_disc_feat * 2,\n",
    "                kern_size,\n",
    "                4,\n",
    "                disc_padding_size,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_disc_feat * 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(\n",
    "                num_disc_feat * 2,\n",
    "                num_disc_feat * 4,\n",
    "                kern_size,\n",
    "                disc_stride,\n",
    "                disc_padding_size,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_disc_feat * 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(\n",
    "                num_disc_feat * 4,\n",
    "                1,\n",
    "                kern_size,\n",
    "                disc_stride,\n",
    "                disc_padding_size,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        for layer in self.net.modules():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.normal_(layer.weight, mean, std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.net(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.ngpu = ngpu\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                dim_z, num_gen_feat * 4, kern_size, 1, 0, bias=False\n",
    "            ),\n",
    "            # ConvTranspose2d are the fractionally strided convolutions used for upscaling mentioned in the paper\n",
    "            nn.BatchNorm2d(num_gen_feat * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                num_gen_feat * 4, num_gen_feat * 2, kern_size, 2, 1, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_gen_feat * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                num_gen_feat * 2, num_gen_feat, kern_size, 2, 1, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_gen_feat),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                num_gen_feat, num_in_channels, kern_size, 2, 1, bias=False\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        for layer in self.net.modules():\n",
    "            if isinstance(layer, nn.ConvTranspose2d):\n",
    "                nn.init.normal_(layer.weight, mean, std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.net(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/adityatandon/Documents/VS Code/Deep_Learning/Data/CIFAR10/cifar-10-batches-py/test_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/adityatandon/Documents/VS Code/Deep_Learning/Tests/GAN_test.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_sampler \u001b[39m=\u001b[39m DistributedSampler(train_dataset, num_replicas\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, rank\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     dataset\u001b[39m=\u001b[39mtrain_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     sampler\u001b[39m=\u001b[39mtrain_sampler,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m val_dataset \u001b[39m=\u001b[39m ValDataset(data_dir_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m val_sampler \u001b[39m=\u001b[39m DistributedSampler(val_dataset, num_replicas\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, rank\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     dataset\u001b[39m=\u001b[39mval_dataset,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     sampler\u001b[39m=\u001b[39mval_sampler,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n",
      "\u001b[1;32m/Users/adityatandon/Documents/VS Code/Deep_Learning/Tests/GAN_test.ipynb Cell 11\u001b[0m in \u001b[0;36mValDataset.__init__\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data_dir):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_data \u001b[39m=\u001b[39m unpickle(data_dir)\n",
      "\u001b[1;32m/Users/adityatandon/Documents/VS Code/Deep_Learning/Tests/GAN_test.ipynb Cell 11\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munpickle\u001b[39m(file):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m fo:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(fo, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbytes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityatandon/Documents/VS%20Code/Deep_Learning/Tests/GAN_test.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/adityatandon/Documents/VS Code/Deep_Learning/Data/CIFAR10/cifar-10-batches-py/test_batch'"
     ]
    }
   ],
   "source": [
    "train_dataset = TrainDataset(data_dir)\n",
    "train_sampler = DistributedSampler(train_dataset, num_replicas=1, rank=0)\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    sampler=train_sampler,\n",
    ")\n",
    "\n",
    "val_dataset = ValDataset(data_dir_val)\n",
    "val_sampler = DistributedSampler(val_dataset, num_replicas=1, rank=0)\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    sampler=val_sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, data_dir, data_dir_val, device, train=True, **kwargs):\n",
    "\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    train_dataset = TrainDataset(data_dir)\n",
    "    train_sampler = DistributedSampler(train_dataset, num_replicas=1, rank=0)\n",
    "    batch_size = kwargs.get(\"batch_size\", 100)\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler,\n",
    "    )\n",
    "    if train == False:\n",
    "        val_dataset = ValDataset(data_dir_val)\n",
    "        val_sampler = DistributedSampler(val_dataset, num_replicas=1, rank=0)\n",
    "        val_loader = DataLoader(\n",
    "            dataset=val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "            sampler=val_sampler,\n",
    "        )\n",
    "\n",
    "    optimG = torch.optim.Adam(gen.parameters(), lr=2e-4, betas=(0.5, 0.0))\n",
    "    optimD = torch.optim.Adam(disc.parameters(), lr=2e-4, betas=(0.5, 0.0))\n",
    "    # optimD = torch.optim.SGD(disc.parameters(), lr=2e-4)\n",
    "\n",
    "    # noise = torch.randn(28, dim_z, 1, 1, device=device)\n",
    "\n",
    "    # real_label = 1\n",
    "    # fake_label = 0\n",
    "    loss_d, loss_g = [], []\n",
    "    \n",
    "    if train:\n",
    "        for i in range(num_epochs):\n",
    "            print(f\"Epoch no. :  {i+1}\")\n",
    "            for j, mini_batch in enumerate(train_loader):\n",
    "                optimG.zero_grad()\n",
    "\n",
    "                for _ in range(3):\n",
    "                    optimD.zero_grad()\n",
    "\n",
    "                    # train disc first\n",
    "                    x_real = mini_batch[\"img\"].to(device)\n",
    "                    x_real = x_real.view(batch_size, num_in_channels, 32, 32)\n",
    "                    labels = torch.full(\n",
    "                        (batch_size,), 1.0, dtype=torch.float32, device=device\n",
    "                    )\n",
    "                    # out_disc_r = disc(x_real).flatten().sigmoid()\n",
    "                    out_disc_r = disc(x_real).flatten()\n",
    "\n",
    "                    # print(out_disc_r)\n",
    "                    loss_disc_r = loss_fn(out_disc_r, labels)\n",
    "                    loss_disc_r.backward()\n",
    "\n",
    "                    x_fake = gen(torch.randn(batch_size, dim_z, 1, 1))\n",
    "                    labels = torch.full(\n",
    "                        (batch_size,), 0.0, dtype=torch.float32, device=device\n",
    "                    )\n",
    "                    # out_disc_f = disc(x_fake).flatten().sigmoid()\n",
    "                    out_disc_f = disc(x_fake).flatten()\n",
    "                    loss_disc_f = loss_fn(out_disc_f, labels)\n",
    "                    loss_disc_f.backward()\n",
    "\n",
    "                    loss_disc = (\n",
    "                        loss_disc_f.mean().item() + loss_disc_r.mean().item()\n",
    "                    ) / 2.0\n",
    "                    \n",
    "                    optimD.step()\n",
    "\n",
    "                # train gen\n",
    "                x_gen = gen(torch.randn(batch_size, dim_z, 1, 1))\n",
    "                # out = disc(x_gen).flatten().sigmoid()\n",
    "                out = disc(x_gen).flatten()\n",
    "                labels = torch.full(\n",
    "                    (batch_size,), 1.0, dtype=torch.float32, device=device\n",
    "                )\n",
    "                loss_gen = loss_fn(out, labels)\n",
    "                loss_gen.backward()\n",
    "\n",
    "                loss_d.append(loss_disc)\n",
    "                loss_g.append(loss_gen.item())\n",
    "\n",
    "                if j % 200 == 0:\n",
    "                    print(f\"Discriminator loss after {j} steps = {loss_d[j + i*train_dataset.__len__()//batch_size]}\")\n",
    "                    print(f\"Generator loss after {j} steps = {loss_g[j + i*train_dataset.__len__()//batch_size]}\")\n",
    "\n",
    "                \n",
    "                optimG.step()\n",
    "                \n",
    "    return loss_d, loss_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator().to(device)\n",
    "gen = Generator().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_d, loss_g = train(3, data_dir=data_dir,data_dir_val=data_dir_val, device=device, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_d)\n",
    "plt.plot(loss_g)\n",
    "plt.legend([\"Discriminator loss\", \"Generator loss\"])\n",
    "plt.show()\n",
    "# plt., loss_d[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    gen_img = gen(torch.randn(10, dim_z, 1, 1))\n",
    "    print(gen_img.shape)\n",
    "    plt.imshow(gen_img[1].reshape(32, 32, 3).detach().numpy())\n",
    "    print(disc(gen_img).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "train_dataset = TrainDataset(data_dir)\n",
    "train_sampler = DistributedSampler(train_dataset, num_replicas=1, rank=0)\n",
    "batch_size = 50\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    sampler=train_sampler,\n",
    ")\n",
    "if train == False:\n",
    "    val_dataset = ValDataset(data_dir_val)\n",
    "    val_sampler = DistributedSampler(val_dataset, num_replicas=1, rank=0)\n",
    "    val_loader = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        sampler=val_sampler,\n",
    "    )\n",
    "\n",
    "optimG = torch.optim.Adam(gen.parameters(), lr=2e-4, betas=(0.5, 0.0))\n",
    "optimD = torch.optim.Adam(disc.parameters(), lr=2e-4, betas=(0.5, 0.0))\n",
    "\n",
    "# for j, mini_batch in enumerate(train_loader):\n",
    "mini_batch = next(iter(train_loader))\n",
    "optimG.zero_grad()\n",
    "\n",
    "for _ in range(3):\n",
    "    optimD.zero_grad()\n",
    "\n",
    "    # train disc first\n",
    "    x_real = mini_batch[\"img\"].to(device)\n",
    "    x_real = x_real.view(batch_size, num_in_channels, 32, 32)\n",
    "    labels = torch.full(\n",
    "        (batch_size,), 1.0, dtype=torch.float32, device=device\n",
    "    )\n",
    "    # out_disc_r = disc(x_real).flatten().sigmoid()\n",
    "    out_disc_r = disc(x_real).flatten()\n",
    "\n",
    "    # print(out_disc_r)\n",
    "    loss_disc_r = loss_fn(out_disc_r, labels)\n",
    "    loss_disc_r.backward()\n",
    "\n",
    "    x_fake = gen(torch.randn(batch_size, dim_z, 1, 1))\n",
    "    labels = torch.full(\n",
    "        (batch_size,), 0.0, dtype=torch.float32, device=device\n",
    "    )\n",
    "    # out_disc_f = disc(x_fake).flatten().sigmoid()\n",
    "    out_disc_f = disc(x_fake).flatten()\n",
    "    loss_disc_f = loss_fn(out_disc_f, labels)\n",
    "    loss_disc_f.backward()\n",
    "\n",
    "    loss_disc = (\n",
    "        loss_disc_f.mean().item() + loss_disc_r.mean().item()\n",
    "    ) / 2.0\n",
    "    if _ != 2:\n",
    "        optimD.step()\n",
    "\n",
    "# train gen\n",
    "x_gen = gen(torch.randn(batch_size, dim_z, 1, 1))\n",
    "# out = disc(x_gen).flatten().sigmoid()\n",
    "out = disc(x_gen).flatten()\n",
    "labels = torch.full(\n",
    "    (batch_size,), 1.0, dtype=torch.float32, device=device\n",
    ")\n",
    "loss_gen = loss_fn(out, labels)\n",
    "loss_gen.backward()\n",
    "\n",
    "\n",
    "# optimG.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gpu, args):\n",
    "    rank = args.nr * args.gpus + gpu\n",
    "    torch.distributed.init_process_group(\n",
    "        backend=\"nccl\",\n",
    "        init_method=\"env://\",\n",
    "        world_size=args.world_size,\n",
    "        rank=rank,\n",
    "    )\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.set_device(gpu)\n",
    "    model = test_net().cuda(gpu)\n",
    "\n",
    "    batch_size = 100\n",
    "\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=1e4)\n",
    "    model = nn.parallel.DistributedDataParallel(model, device_ids=[gpu])\n",
    "    # model, optimizer = amp.initialize(model, optimizer, opt_level=\"O2\")\n",
    "    # model = DDP(model)\n",
    "\n",
    "    total_steps = len(train_loader)\n",
    "    for epoch in range(args.epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.cuda(non_blocking=True)\n",
    "            labels = labels.cuda(non_blocking=True)\n",
    "\n",
    "            if (i + 1) % 100 == 0 and gpu == 0:\n",
    "                print(\n",
    "                    \"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\".format(\n",
    "                        epoch + 1, args.epochs, i + 1, total_steps, loss.item()\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
