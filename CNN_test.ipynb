{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.backends.mps\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.cm as cm\n",
    "from torch.autograd.anomaly_mode import set_detect_anomaly\n",
    "\n",
    "params = {'font.size' : 16 }\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 30\n",
    "padding_size = 2\n",
    "filter_size = 3\n",
    "step_size = 1\n",
    "num_features = 2\n",
    "num_connected_layers = 10\n",
    "num_conv_layers = 3\n",
    "num_classifications = 10\n",
    "num_neurons_per_layer = 50\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    torch.dtype=torch.float32\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "torch.autograd.anomaly_mode.set_detect_anomaly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/Users/adityatandon/Documents/VS Code/Learn ML/Data/MNIST/mnist_train.csv\")\n",
    "test_data = pd.read_csv(\"/Users/adityatandon/Documents/VS Code/Learn ML/Data/MNIST/mnist_test.csv\")\n",
    "test_img = torch.tensor(train_data.iloc[0].to_list()[1:], dtype=torch.float32, device=device).view(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_img.to(\"cpu\"), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv Layer using normal for loops\n",
    "class Conv_layer2():\n",
    "    def __init__(self, filter_size:int, num_features: int, device=device):\n",
    "        self.device = device\n",
    "        self.num_features = num_features\n",
    "        self.kernel = torch.randn(num_features, filter_size, filter_size, dtype=torch.float32, device=self.device)\n",
    "        # self.kernel = torch.tensor([[[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], [[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]], dtype=torch.float32, device=device)\n",
    "        # # print(padded_image.shape, self.kernel.shape)\n",
    "        self.bias = torch.randn(filter_size, filter_size, dtype=torch.float32, device=self.device)\n",
    "        print(self.kernel)\n",
    "\n",
    "    def convolve(self, image: torch.tensor):\n",
    "        # self.kernel = torch.flip(self.kernel, dims=(0,))\n",
    "        start_time = time.time()\n",
    "        if(image.dim() <= 2):\n",
    "            unsqueezed_img = image.unsqueeze(dim=0)\n",
    "        else:\n",
    "            unsqueezed_img = image\n",
    "        padded_image = nn.functional.pad(unsqueezed_img, (filter_size - 1, filter_size - 1, filter_size - 1, filter_size - 1, 0, 0))\n",
    "        # print(padded_image.shape, padded_image[0, :10, :10])\n",
    "        conv_img = torch.zeros(size=(num_features*unsqueezed_img.shape[0], unsqueezed_img.shape[1], unsqueezed_img.shape[2]), device=self.device)\n",
    "        for feat in range(num_features):\n",
    "            for k in range(padded_image.shape[0]):\n",
    "                for i in range(padded_image.shape[1] - self.kernel[feat].shape[0]):\n",
    "                    for j in range(padded_image.shape[2] - self.kernel[feat].shape[1]):\n",
    "                        pixels = padded_image[k, i:i + self.kernel[feat].shape[0], j:j + self.kernel[feat].shape[1]]\n",
    "                        conv = pixels * self.kernel[feat]\n",
    "                        conv += self.bias\n",
    "                        conv_img[feat, i:i + self.kernel[feat].shape[0] - step_size, j:j + self.kernel[feat].shape[1] - step_size] += torch.sum(conv)\n",
    "                        # conv_img[feat, i:i + 1, j:j + 1] += torch.sum(conv)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(end_time - start_time)\n",
    "        return conv_img, self.kernel\n",
    "    \n",
    "    def pool(self, step_size: int, conv_img: torch.tensor):\n",
    "        pool_kern = torch.ones(step_size, step_size, device=self.device)\n",
    "        pool_size = [conv_img.shape[-3], int((conv_img.shape[-2] - step_size)/step_size + 1), int((conv_img.shape[-1] - step_size)/step_size + 1)]\n",
    "        pool_img = torch.zeros(pool_size, device=device)\n",
    "        for feat in range(num_features):\n",
    "            row = 0\n",
    "            for i in range(pool_img.shape[-2]):\n",
    "                col = 0\n",
    "                for j in range(pool_img.shape[-1]):\n",
    "                    pixels = conv_img[feat, row:row + step_size, col:col + step_size]\n",
    "                    conv = pixels * pool_kern\n",
    "                    pool_img[feat, i, j] = torch.max(conv)\n",
    "                    col += step_size \n",
    "                    \n",
    "                row += step_size \n",
    "        return pool_img\n",
    "    \n",
    "    def forward(self, image: torch.tensor, step_size: int):\n",
    "        conv_img, kernel = self.convolve(image)\n",
    "        out = conv_img.relu()\n",
    "        return out\n",
    "    \n",
    "    # def train(self, x, )\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = Conv_layer2(filter_size=filter_size, num_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_img, kernel = conv_layer.convolve(image=test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_img = conv_layer.pool(step_size=step_size, conv_img=conv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10,10))\n",
    "ax[0].imshow(conv_img[0].to(\"cpu\"), cmap='gray')\n",
    "ax[1].imshow(pool_img[0].to(\"cpu\"), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multi dimensioanl images with a step size of 1 - 1:1 image to conved_image size; dimensions increase by 2\n",
    "# convolution using a matrix multiplication\n",
    "class Convolver:\n",
    "    \n",
    "    def __init__(self, kern, bias, x, device=device) -> None:\n",
    "        \n",
    "        if(x.dim() <= 2):\n",
    "            self.img = x.unsqueeze(dim=1)\n",
    "        else:\n",
    "            self.img = x\n",
    "        # print(self.img.shape)\n",
    "        # self.w = torch.randn(num_features * self.img.shape[-3], filter_size, filter_size, requires_grad=True, dtype=torch.float32, device=device)\n",
    "        # self.b = torch.randn(self.img.shape[-1] * self.img.shape[-2], requires_grad=True, dtype=torch.float32, device=device)\n",
    "        self.w = kern\n",
    "        # print(self.w.shape)\n",
    "        self.b = bias\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def flatten_pad(self):\n",
    "        \n",
    "        pad_size = int((filter_size - 1) / 2) \n",
    "        img = nn.functional.pad(self.img, (pad_size, pad_size, pad_size, pad_size))\n",
    "        print(img.shape)\n",
    "        n = torch.zeros(2)\n",
    "        for i in range(2):\n",
    "            n[i] = ((img.shape[-i - 1] - filter_size) / step_size) + 1\n",
    "        # print(n)\n",
    "        # flat_img = img.flatten().clone().detach().view(img.shape[-3], img.shape[-2]*img.shape[-1]).float()\n",
    "        flat_img = img.flatten().clone().view(img.shape[-4], img.shape[-3], img.shape[-2]*img.shape[-1]).float()\n",
    "        # flat_kern = self.w.view(num_features * self.img.shape[-3], filter_size * filter_size)\n",
    "        # print(\"img shape = \",self.img.shape)\n",
    "        flat_kern = self.w.view(self.w.shape[-3], filter_size * filter_size)\n",
    "        # print(\"flat kern shape = \", flat_kern.shape)\n",
    "        return n, img, flat_img, flat_kern\n",
    "    \n",
    "\n",
    "    def change_kern_multi(self):\n",
    "\n",
    "        n, img, flat_img, flat_kern = self.flatten_pad()\n",
    "\n",
    "        new_kern = torch.zeros(self.w.shape[-3] , int(torch.prod(n)), img.shape[-2] * img.shape[-1], device=device) #produces num_feat x n x n convolution\n",
    "        # print(\"changed kern shape = \", new_kern.shape)\n",
    "        flat_kern = torch.cat([flat_kern for _ in range(1)], dim=0)\n",
    "        # print(\"flat kern_cat shape = \", flat_kern.shape)\n",
    "\n",
    "        for k  in range(new_kern.shape[-3]):\n",
    "            start_idx = 0\n",
    "            for i in range(new_kern.shape[-2]):\n",
    "                j = 0\n",
    "                c = 0\n",
    "                if i == 0:\n",
    "                    start_idx = start_idx\n",
    "                elif i % int(n[0]) != 0:\n",
    "                    start_idx += step_size * step_size\n",
    "                else: \n",
    "                    start_idx = int((i+1-step_size)//int(n[0]) * img.shape[-2])\n",
    "\n",
    "                while j < new_kern.shape[-1] and start_idx+j+filter_size <= new_kern.shape[-1]:\n",
    "                    new_kern[k][i][start_idx + j:start_idx + j + filter_size] = flat_kern[k][c:c + filter_size]\n",
    "                    c += filter_size\n",
    "                    j += img.shape[-2]\n",
    "                    if c == flat_kern.shape[-1]:\n",
    "                        break\n",
    "        return n, new_kern, flat_img\n",
    "    \n",
    "    def convolve(self): #convolves image using a kernel made from self.w\n",
    "        start_time = time.time()\n",
    "        # conved_final = torch.empty(batch_size, num_features*self.img.shape[-3], self.img.shape[-2], self.img.shape[-1]) \n",
    "        # for i in range(batch_size):\n",
    "        conved_final = []\n",
    "        n, changed_kern, flat_img = self.change_kern_multi()\n",
    "        # print(\"flat img shape = \", flat_img.shape)\n",
    "        to_be_cat = [flat_img for _ in range(self.img.shape[-3])]\n",
    "        copy_flat_img = torch.cat(to_be_cat, dim=1).unsqueeze(dim=-2)\n",
    "        # print(\"copy flat img shape\",copy_flat_img.shape)\n",
    "        # print(changed_kern.shape, \"changed_kern\")\n",
    "        # copy_flat_img = flat_img\n",
    "        # conved_final = changed_kern @ copy_flat_img[:][0].to(self.device)\n",
    "        for batch in range(self.img.shape[-4]):\n",
    "            # torch.stack((conved_final,(changed_kern @ copy_flat_img[batch][i]).unsqueeze(dim=-1).to(self.device)), dim=1)\n",
    "            conv = [changed_kern @ torch.transpose(copy_flat_img[batch][j], -1, -2) for j in range(self.img.shape[-3])]\n",
    "            conved_final.append(torch.concat(conv, dim=0).squeeze(dim=0))\n",
    "        conved_final = torch.stack(conved_final)\n",
    "        # print(conved_final.shape)\n",
    "        \n",
    "        squeezed_convd_mat = conved_final.squeeze(dim=-1)\n",
    "        squeezed_convd_mat += self.b\n",
    "        # print(squeezed_convd_mat.shape)\n",
    "        \n",
    "        conv_img = squeezed_convd_mat.reshape(batch_size, self.img.shape[-3] * num_features, int(n[-2]), int(n[-1]))\n",
    "\n",
    "        end_time = time.time()\n",
    "        # print(end_time - start_time)\n",
    "        return conv_img #returns convolved image \n",
    "    \n",
    "    def pool(self, step_size: int, conv_img: torch.tensor):\n",
    "        pool_kern = torch.ones(step_size, step_size, device=self.device)\n",
    "        pool_size = [conv_img.shape[-4], conv_img.shape[-3], int((conv_img.shape[-2] - step_size)/step_size + 1), int((conv_img.shape[-1] - step_size)/step_size + 1)]\n",
    "        pool_img = torch.zeros(pool_size, device=device)\n",
    "        for batch in range(conv_img.shape[-4]):\n",
    "            for feat in range(num_features):\n",
    "                row = 0\n",
    "                for i in range(pool_img.shape[-2]):\n",
    "                    col = 0\n",
    "                    for j in range(pool_img.shape[-1]):\n",
    "                        pixels = conv_img[batch, feat, row:row + step_size, col:col + step_size]\n",
    "                        conv = pixels * pool_kern\n",
    "                        pool_img[feat, i, j] = torch.max(conv)\n",
    "                        col += step_size \n",
    "                    row += step_size \n",
    "        return pool_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_bias = torch.randn(1, 28*28, requires_grad=True, dtype=torch.float32, device=device)\n",
    "rand_kern = torch.randn(num_features, filter_size, filter_size, requires_grad=True, dtype=torch.float32, device=device)\n",
    "convolver = Convolver(kern=rand_kern, bias=rand_bias, x=x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conved = convolver.convolve()\n",
    "conved.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,conved.shape[1], figsize=(20,20))\n",
    "for i in range(conved.shape[1]):\n",
    "    ax[i].imshow(conved[0][i].to(\"cpu\").detach().numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, num_neurons, num_inputs_per_neuron, device):\n",
    "        self.w = torch.randn(num_neurons, num_inputs_per_neuron, dtype=torch.float32, requires_grad=True, device=device) \n",
    "        print(self.w.shape)\n",
    "        self.b = torch.randn(num_neurons, 1, dtype=torch.float32, requires_grad=True, device=device) \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        outer = ((self.w @ x) + self.b)\n",
    "        # for i in range(outer.shape[-2]):\n",
    "        #     mean = torch.mean(outer[i, :]).to(device)\n",
    "        #     sd = torch.sqrt(torch.var(outer[i, :])).to(device)\n",
    "        #     outer[i, :] = (outer[i, :] - mean) / sd\n",
    "        out = torch.nn.functional.tanh(outer)\n",
    "        # print(out.shape)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv Layer using calling convolver\n",
    "\n",
    "# commented out w worked\n",
    "\n",
    "class Conv_layer():\n",
    "    def __init__(self, img, filter_size:int, num_features: int, device=device):\n",
    "        \n",
    "        self.device = device\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.w = torch.randn(num_features, filter_size, filter_size, requires_grad=True, dtype=torch.float32, device=self.device) \n",
    "        # self.wel = torch.tensor([[[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], [[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]], dtype=torch.float32, device=device)\n",
    "        # # print(padded_image.shape, self.wel.shape)\n",
    "        self.b = torch.randn(1, img.shape[-1] * img.shape[-2], requires_grad=True, dtype=torch.float32, device=self.device) \n",
    "        self.gamma = torch.randn(1, dtype=torch.float32, device = self.device, requires_grad=True)\n",
    "        self.beta = torch.randn(1, dtype=torch.float32, device = self.device, requires_grad=True)\n",
    "\n",
    "    def convolve(self, image: torch.tensor):\n",
    "        # print(\"kern shape = \", self.w.shape)\n",
    "        convolver = Convolver(kern=self.w, x=image, bias=self.b)\n",
    "        conv_img = convolver.convolve()\n",
    "        return conv_img\n",
    "    \n",
    "    def forward_relu(self, image: torch.tensor):\n",
    "        conv_img = self.convolve(image) \n",
    "        conv_img = self.batch_norm(conv_img)\n",
    "        #batch_norm\n",
    "        # normalised = self.batch_norm(conv_img)\n",
    "        # conv_img = normalised \n",
    "        # conv_img_temp = conv_img.clone() \n",
    "        # for i in range(conv_img_temp.shape[-4]):\n",
    "        #     for j in range(conv_img_temp.shape[-3]):\n",
    "        #         mean = torch.mean(conv_img_temp[i,j,:,:])\n",
    "        #         # variance=torch.zeros(1, requires_grad=True)\n",
    "        #         variance = torch.var(conv_img_temp, dim=-3, keepdim=True)\n",
    "        #         copy = conv_img_temp[i,j,:,:].clone()\n",
    "        #         conv_img_temp[i,j,:,:] = (copy - mean) / torch.sqrt(variance)\n",
    "        out = torch.nn.functional.tanh(conv_img)\n",
    "        return out\n",
    "    \n",
    "    def batch_norm(self, image):\n",
    "        # conv_img_temp = image.clone()\n",
    "        # for i in range(conv_img_temp.shape[-3]):\n",
    "        #     mean = torch.mean(conv_img_temp, dim=-3, keepdim=True)\n",
    "        #     # variance=torch.zeros(1, requires_grad=True)\n",
    "        #     variance = torch.var(conv_img_temp, dim=-3, keepdim=True)\n",
    "        #     normalised = (conv_img_temp[:,i,:,:] - mean) / torch.sqrt(variance + 1e-8)\n",
    "        #     # print(\"conv: \", conv_img_temp.shape)\n",
    "        #     # print(\"mean: \", mean.shape)\n",
    "        #     # print(\"var: \", var.shape)\n",
    "        #     conv_img_temp[:,i,:,:] = normalised\n",
    "        conv_img_temp = image.clone()\n",
    "        \n",
    "        stack = []\n",
    "        for j in range(conv_img_temp.shape[-4]):\n",
    "            # for i in range(conv_img_temp.shape[-3]):  # Iterate over the channel dimension\n",
    "            mean = torch.mean(conv_img_temp, dim=-3, keepdim=True)\n",
    "            variance = torch.var(conv_img_temp, dim=-3, keepdim=True, unbiased=True)\n",
    "            normal = [(conv_img_temp[j][i] - mean) / torch.sqrt(variance + 1e-8) for i in range(conv_img_temp.shape[-3])]\n",
    "            print(normal[0].shape)\n",
    "            stack.append(torch.concat(normal, dim=0))\n",
    "    \n",
    "        conv_img_temp = torch.stack(stack)\n",
    "\n",
    "        return conv_img_temp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pool_Layer:\n",
    "\n",
    "    def __init__(self, device=device):\n",
    "        self.device=device\n",
    "        pass\n",
    "\n",
    "    def pool(self, step_size: int, conv_img: torch.tensor):\n",
    "        pool_kern = torch.ones(step_size, step_size, device=self.device)\n",
    "        pool_size = [batch_size, conv_img.shape[-3], int((conv_img.shape[-2] - step_size)/step_size + 1), int((conv_img.shape[-1] - step_size)/step_size + 1)]\n",
    "        pool_img = torch.zeros(pool_size, device=device)\n",
    "        for feat in range(num_features):\n",
    "            row = 0\n",
    "            for i in range(pool_img.shape[-2]):\n",
    "                col = 0\n",
    "                for j in range(pool_img.shape[-1]):\n",
    "                    pixels = conv_img[:, feat, row:row + step_size, col:col + step_size]\n",
    "                    conv = pixels * pool_kern\n",
    "                    pool_img[:, feat, i, j] = torch.max(conv)\n",
    "                    col += step_size \n",
    "                    \n",
    "                row += step_size \n",
    "        return pool_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    #num_inputs per neuron=batch_size\n",
    "    def __init__(self, num_conected_layers, num_conv_layers, num_neurons_per_layer, \n",
    "                 num_final_out, datagen, batch_size, device=device):\n",
    "        \n",
    "        self.device = device\n",
    "        self.datagen = datagen(1)\n",
    "        img, _ = self.datagen.data_generator()\n",
    "        # print(img.shape)\n",
    "        self.convlayers = [Conv_layer(img, filter_size, num_features)]\n",
    "        for _ in range(1, num_conv_layers):\n",
    "            self.convlayers.append(Conv_layer(img, filter_size, num_features))\n",
    "\n",
    "        self.num_inputs_per_neuron = (img.shape[-1] * img.shape[-2]) * num_features**(num_conv_layers)\n",
    "        # print(\"num_inputs = \", self.num_inputs_per_neuron) \n",
    "\n",
    "        self.layers = [Layer(num_neurons_per_layer, self.num_inputs_per_neuron, device=device)]\n",
    "        for _ in range(1, num_conected_layers-1):\n",
    "            self.layers.append(Layer(num_neurons_per_layer, num_neurons_per_layer, device=device))\n",
    "        self.layers.append(Layer(num_final_out, num_neurons_per_layer, device=device))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        c = 0\n",
    "        out=torch.zeros(1, requires_grad=True)\n",
    "        for i in range(0, num_conv_layers):\n",
    "            if i==0:\n",
    "                out = self.convlayers[0].forward_relu(x)\n",
    "            elif i==num_conv_layers-1:\n",
    "                out = self.convlayers[i].convolve(out)\n",
    "                out = out.reshape(self.num_inputs_per_neuron, batch_size)\n",
    "                print(out.shape)\n",
    "            else:\n",
    "                out = self.convlayers[i].forward_relu(out)\n",
    "\n",
    "        for i in range(0, num_connected_layers):\n",
    "            # print(\"out shape check= \",out.shape)\n",
    "            out = self.layers[i].forward(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def train(self, epochs, learning_rate):\n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        for i in range(epochs):\n",
    "            x, y = self.datagen.data_generator()\n",
    "            out = self.forward(x).view(y.shape[0], y.shape[1])\n",
    "            # out = torch.tensor([-torch.inf if i.item()==0.0 else i for i in out.flatten()], device=device, requires_grad=True).view(y.shape[0], y.shape[1])\n",
    "            loss = loss_func(out, y) \n",
    "            # loss = ((y - out)**2).flatten().sum() \n",
    "            print(f\"Loss: {loss} at epoch: {i}\")\n",
    "            loss.backward()\n",
    "\n",
    "            for conv_layer in self.convlayers:\n",
    "                # w_grad = torch.tensor([c.item() if torch.abs(c) < 1000.0 else 1000.0 for c in conv_layer.w.grad.flatten()], dtype=torch.float, device=self.device)\n",
    "                # print(w_grad, \"\\n\", type(conv_layer.w.grad))\n",
    "                # conv_layer.w.grad = w_grad\n",
    "                # b_grad = torch.tensor([c.item() if torch.abs(c) < 100.0 else 100.0 for c in conv_layer.b.grad.flatten()], dtype=torch.float, device=self.device)\n",
    "                # conv_layer.b.grad = b_grad\n",
    "                conv_layer.w.data -= learning_rate * conv_layer.w.grad\n",
    "                conv_layer.b.data -= learning_rate * conv_layer.b.grad\n",
    "                conv_layer.w.grad = None\n",
    "                conv_layer.b.grad = None\n",
    "                \n",
    "            for layer in self.layers:\n",
    "                layer.w.data -= learning_rate * layer.w.grad\n",
    "                layer.b.data -= learning_rate * layer.b.grad\n",
    "                layer.w.grad = None\n",
    "                layer.b.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datagen:\n",
    "    def __init__(self, batch_size) -> None:\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def data_generator(self, fix_seed=False, train=True):\n",
    "        if fix_seed==True:\n",
    "            seed_idx = torch.tensor(int(input(\"Enter seed index number\")))\n",
    "        else:\n",
    "            seed_idx = (torch.randint(low=0, high=len(train_data) - self.batch_size, size=(1,1))).item()\n",
    "        \n",
    "        if train:\n",
    "            y_out = torch.tensor(train_data['label'].iloc[seed_idx:seed_idx+self.batch_size].to_numpy()).to(device)\n",
    "            x = (torch.tensor(train_data.iloc[seed_idx:seed_idx+self.batch_size, 1:].to_numpy()).view(self.batch_size, 1, 28, 28).to(device))\n",
    "        else:\n",
    "            y_out = torch.tensor(test_data['label'].iloc[seed_idx:seed_idx+self.batch_size].to_numpy()).to(device)\n",
    "            x = (torch.tensor(test_data.iloc[seed_idx:seed_idx+self.batch_size, 1:].to_numpy()).view(batch_size, 1, 28, 28).to(device))\n",
    "            \n",
    "\n",
    "        def one_hot_encoder(y):\n",
    "            y_out = []\n",
    "            for i in y:\n",
    "                # num = np.array([-torch.inf for _ in range(num_classifications)])\n",
    "                num = np.zeros(num_classifications)\n",
    "                num[i] = 1\n",
    "                y_out.append(num)\n",
    "            return(torch.tensor(np.array(y_out), dtype=torch.float32)).to(device)\n",
    "\n",
    "        # embedding = nn.Embedding(num_classifications, emb_dim, device=device)\n",
    "        # y_out = torch.transpose(embedding(y_out), 0, 1)\n",
    "        y_out = one_hot_encoder(y_out)\n",
    "        return x, y_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = Datagen(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = datagen.data_generator()\n",
    "print(x.shape, y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(num_connected_layers, num_conv_layers, num_neurons_per_layer, num_classifications, Datagen, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.forward(x=x).view(y.shape[0], y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.train(epochs=200, learning_rate=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ten[:, 0,:,:] / torch.var(test_ten, dim=-3, keepdim=True), test_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn.convlayers[1].w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pool_layer:\n",
    "    def __init__(self, x, device=device):\n",
    "        self.device = device\n",
    "        pass\n",
    "\n",
    "    def pool(self, step_size: int, conv_img: torch.tensor):\n",
    "        pool_kern = torch.ones(step_size, step_size, device=self.device)\n",
    "        pool_size = [conv_img.shape[-3], int((conv_img.shape[-2] - step_size)/step_size + 1), int((conv_img.shape[-1] - step_size)/step_size + 1)]\n",
    "        pool_img = torch.zeros(pool_size, device=device)\n",
    "        for feat in range(num_features):\n",
    "            row = 0\n",
    "            for i in range(pool_img.shape[-2]):\n",
    "                col = 0\n",
    "                for j in range(pool_img.shape[-1]):\n",
    "                    pixels = conv_img[feat, row:row + step_size, col:col + step_size]\n",
    "                    conv = pixels * pool_kern\n",
    "                    pool_img[feat, i, j] = torch.max(conv)\n",
    "                    col += step_size \n",
    "                    \n",
    "                row += step_size \n",
    "        return pool_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multi dimensioanl images, conved img size != img size, reduces size by 2 but increases dims by 2\n",
    "# convolution using a toeplitz matrix\n",
    "class Convolver2:\n",
    "    \n",
    "    def __init__(self, kernel, x, bias, device=device) -> None:\n",
    "        self.kern = torch.randn(num_features, filter_size, filter_size, requires_grad=True, dtype=torch.float32, device=device)\n",
    "        print(\"Kern = \\n\", self.kern)\n",
    "        if(x.dim() <= 2):\n",
    "            self.img = x.unsqueeze(dim=0)\n",
    "        else:\n",
    "            self.img = x\n",
    "\n",
    "    def find_n(self, i, n):\n",
    "        if n >= 0 :\n",
    "            end_pos = self.kern.shape[i] - 1 + ((n-1) * step_size) \n",
    "            if end_pos >= (self.img.shape[i] - 1):\n",
    "                return n\n",
    "            else:\n",
    "                return self.find_n(i, n+1)\n",
    "        else:\n",
    "            print(\"Initialise n above or equal to 0\") \n",
    "            return -9999\n",
    "\n",
    "\n",
    "    def get_n_flatten_pad(self):\n",
    "        n = torch.zeros(2)\n",
    "        for i in range(n.shape[0]):\n",
    "            n[i] = self.find_n(-i - 1, n[i])\n",
    "            \n",
    "        self.bias = torch.randn(int(torch.prod(n)), requires_grad=True, dtype=torch.float32, device=device)\n",
    "        test_pad_0 = filter_size + (int(n[-1].item()) - 1) * step_size - self.img.shape[-1]\n",
    "        test_pad_1 = filter_size + (int(n[-2].item()) - 1) * step_size - self.img.shape[-2]\n",
    "        print(test_pad_0)\n",
    "        pad_black = nn.functional.pad(self.img, (0, test_pad_0, 0, test_pad_1))\n",
    "        # pad_black = nn.functional.pad(self.img, (1, 1, 1, 1))\n",
    "        # n = torch.zeros(2)\n",
    "        # for i in range(2):\n",
    "        #     n[i] = ((pad_black.shape[-i - 1] - filter_size) / step_size) + 1\n",
    "        \n",
    "        flat_pad_black = pad_black.flatten().clone().detach().view(pad_black.shape[-3], pad_black.shape[-2]*pad_black.shape[-1]).float()\n",
    "\n",
    "        flat_kern = self.kern.view(num_features, filter_size * filter_size)\n",
    "\n",
    "        return n, pad_black, flat_pad_black, flat_kern, test_pad_0, test_pad_1\n",
    "    \n",
    "\n",
    "    def change_kern_multi(self):\n",
    "        n, pad_black, flat_pad_black, flat_kern, test_pad_0, test_pad_1 = self.get_n_flatten_pad()\n",
    "\n",
    "        new_kern = torch.zeros(num_features * self.img.shape[-3], int(torch.prod(n).item()), pad_black.shape[-2] * pad_black.shape[-1], device=device) #produces num_feat x n x n convolution\n",
    "        print(new_kern.shape)\n",
    "\n",
    "        flat_kern = torch.cat([flat_kern, flat_kern], dim=0)\n",
    "        print(flat_kern.shape)\n",
    "        print(\"n = \", n)\n",
    "        print(\"Pad_ =\", pad_black.shape)\n",
    "\n",
    "        for k  in range(new_kern.shape[-3]):\n",
    "\n",
    "            num_steps = 0\n",
    "            start_idx = 0\n",
    "            for i in range(new_kern.shape[-2]):\n",
    "\n",
    "\n",
    "                j = 0\n",
    "                c = 0\n",
    "                if i == 0:\n",
    "                    start_idx = start_idx\n",
    "                elif num_steps % int(n[0].item()) != 0:\n",
    "                # elif i % int(n[0].item()) != 0:\n",
    "                    start_idx += step_size\n",
    "                else: \n",
    "                    start_idx += (filter_size - 1) + pad_black.shape[-2]\n",
    "                    # start_idx = int(i//int(n[0].item()) * pad_black.shape[-2])\n",
    "                    \n",
    "\n",
    "                \n",
    "                # while j < new_kern.shape[-1] and start_idx+j < new_kern.shape[-1]:\n",
    "                while j < new_kern.shape[-1] and start_idx+j+filter_size <= new_kern.shape[-1]:\n",
    "                    # print(start_idx + j)\n",
    "                    new_kern[k][i][start_idx + j:start_idx + j + filter_size] = flat_kern[k][c:c + filter_size]\n",
    "                    c += filter_size\n",
    "                    j += pad_black.shape[-2]\n",
    "                    if c == flat_kern.shape[-1]:\n",
    "                        break\n",
    "                \n",
    "                num_steps += 1\n",
    "                \n",
    "        return new_kern, flat_pad_black, n, test_pad_0, test_pad_1\n",
    "    \n",
    "    def convolve(self):\n",
    "    \n",
    "        start_time = time.time()\n",
    "\n",
    "        changed_kern, flat_pad_black, n, test_pad_0, test_pad_1 = self.change_kern_multi()\n",
    "        print(\"changed_kern = \",changed_kern.shape)\n",
    "\n",
    "        copy_flat_img = torch.cat([flat_pad_black, flat_pad_black], dim=0)\n",
    "        print(copy_flat_img.shape)\n",
    "\n",
    "        conved_mat = changed_kern @ copy_flat_img.unsqueeze(dim=-1) \n",
    "\n",
    "        print(conved_mat.shape)\n",
    "\n",
    "        squeezed_convd_mat = conved_mat.squeeze(dim=-1)\n",
    "        \n",
    "        mat_conv_test = torch.zeros(squeezed_convd_mat.shape, device=device)\n",
    "        print(\"squeezed_convd_mat shape = \",squeezed_convd_mat.shape)\n",
    "\n",
    "        # shifting back the shifted pixels because of the padding\n",
    "        # mat_conv_test[:, :mat_conv_test.shape[-1] - (test_pad_0 + test_pad_1 - 1)] = squeezed_convd_mat[:, (test_pad_0 + test_pad_1 - 1):]\n",
    "        # mat_conv_test[:, mat_conv_test.shape[-1] - (test_pad_0 + test_pad_1 - 1):] = squeezed_convd_mat[:, 0:(test_pad_0 + test_pad_1 - 1)]\n",
    "\n",
    "        # conv_img = mat_conv_test.reshape(num_features * self.img.shape[-3], int(n[-2].item()), int(n[-1].item()))\n",
    "        conv_img = squeezed_convd_mat.reshape(num_features * self.img.shape[-3], int(n[-2].item()), int(n[-1].item()))\n",
    "        end_time = time.time()\n",
    "        print(end_time - start_time)\n",
    "        return conv_img, n, changed_kern #returns convolved image \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
